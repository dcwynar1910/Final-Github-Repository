SP25-DS677852 Deep Learning

Group Number:  20
Meeting Time:  5th April, 11:00 am
Project Name: Whale Sound Classification Algorithm
Project Proposal (200 words max): We aim to develop a deep learning model that classifies 2-second audio clips, distinguishing whale sounds from other noises. The approach involves converting each sound clip into a 2D image representation using a Short-Time Fourier Transform (STFT). These spectrogram images serve as input for a convolutional neural network (CNN) based on modern Inception blocks. By leveraging this architecture, the model can effectively learn complex patterns and improve classification accuracy.

Dataset(s) being considered: https://github.com/TarinZ/whale-detector?tab=readme-ov-fileLinks

GitHub Repository Link: https://github.com/javadahut/Final-Github-Repository

Work Split Details:  The work will have the following key stages: data acquisition and processing, vectorization, embedding, development of a baseline model, training the baseline model on the dataset, constructing an enhanced model incorporating dropout, training the updated model, and conducting a comparative evaluation to assess performance improvements. We plan to contribute equally to each stage that is listed above.

Project 1: CNN (InceptionV1) + STFT based Whale Detection Algorithm

https://github.com/TarinZ/whale-detector?tab=readme-ov-fileLinks to an external site.



What the project accomplishes:

This project aims to be able to detect if whale signals are present in water based on a 2-second sound clip where the label is either yes or no that a whale is present.



In what way you believe it is innovative:

I think that this project is innovative because it uses only a 2-second sound clip to distinguish something that can be mistaken for practically anything and differentiates it and classifies it. Further, it converts this sound clip into a 2d image using Short-Time-Fourier-Transform (STFT), which will then be used as training data for a CNN. In fact, it is uses modern CNN Inception blocks which ultimately can be classified as a deep learning model.



What excites you about it:

What excites me about the algorithm is that in my eyes it is incredible how with 2 seconds of audio it can detect a signal from a whale. In addition, it is modern and has a creative approach, using a transformation to manipulate the data to be used in a CNN.



Any possible uses you could imagine or be interested in:

With this algorithm and theory, there are endless possibilities for use. I recently saw a movie about someone lost in the tundra and perhaps their calling out can be symbolized as the whale signal in our current situation, for them to be eventually saved. Another use case could be having a longer audio and determining whether an event is happening somewhere in space for example a black hole or supernova.
